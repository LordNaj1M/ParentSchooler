{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dcf744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_name() :\n",
    "    '''\n",
    "    Extract article's name\n",
    "    ----\n",
    "    Args : - \n",
    "    Output : list of article's name\n",
    "    '''\n",
    "    WebDriverWait(driver, 15).until(EC.visibility_of_element_located((By.XPATH, \"//div[@class='title']\")))\n",
    "    articles_name_raw = driver.find_elements(By.XPATH, \"//div[@class='title']\")\n",
    "\n",
    "    articles_name = []\n",
    "\n",
    "    for i in range (len(articles_name_raw)) : \n",
    "        article_name = articles_name_raw[i].text \n",
    "        articles_name.append(article_name)\n",
    "\n",
    "    return articles_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_link(journal_link) :\n",
    "    '''\n",
    "    Extract article's link\n",
    "    ----\n",
    "    Args : link of the journal\n",
    "    Output : list of article's link\n",
    "    '''\n",
    "    response = requests.get(journal_link)\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        html_content = response.content\n",
    "        parsed_html = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        # Find links\n",
    "        links = parsed_html.find_all('a')\n",
    "        \n",
    "        articles_link = []\n",
    "        \n",
    "        for link in links : \n",
    "            href_link = link.get('href')\n",
    "            if (len(href_link) == 58 or len(href_link) == 57) and href_link[:53] == 'https://jurnal.ipb.ac.id/index.php/jikk/article/view/' :\n",
    "                articles_link.append(href_link)\n",
    "            else :\n",
    "                continue\n",
    "        return articles_link\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58eee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_articles_link(journal_link) :\n",
    "    '''\n",
    "    Extract pdf's link of an article \n",
    "    ----\n",
    "    Args : link of the journal\n",
    "    Output : list of pdf's link\n",
    "    '''\n",
    "    response = requests.get(journal_link)\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        html_content = response.content\n",
    "        parsed_html = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        # Find links\n",
    "        links = parsed_html.find_all('a')\n",
    "        \n",
    "        pdf_articles_link = []\n",
    "        \n",
    "        for link in links : \n",
    "            href_link = link.get('href')\n",
    "            if (  61 <= len(href_link) <= 64 or 68 <= len(href_link) <= 69) and href_link[:53] == 'https://jurnal.ipb.ac.id/index.php/jikk/article/view/' :\n",
    "                pdf_articles_link.append(href_link)\n",
    "            else :\n",
    "                continue\n",
    "        return pdf_articles_link\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a1bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abstracts(articles_link) :\n",
    "    '''\n",
    "    Extract abstract from an article\n",
    "    ----\n",
    "    Args : link of the articles\n",
    "    Output : list of abstracts\n",
    "    '''\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    abstracts = []\n",
    "    results = articles_link.copy()\n",
    "    for i in range (len(results)) : \n",
    "        driver.get(results[i])\n",
    "        WebDriverWait(driver, 15).until(EC.visibility_of_element_located((By.XPATH, \"//div[@class='item abstract']\")))\n",
    "        abstract = driver.find_element(By.XPATH, \"//div[@class='item abstract']\").text.split(\"\\n\")[1]\n",
    "        abstracts.append(abstract)\n",
    "        \n",
    "    return abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(list_articles_name, list_pdf_articles, list_abstracts) :\n",
    "    '''\n",
    "    Convert into dataframe\n",
    "    ----\n",
    "    Args : list article's name, list pdf's link of articles, list abstracts of articles\n",
    "    Output : dataframe \n",
    "    '''\n",
    "    data = {'pdf_article_link': list_pdf_articles, 'article_name': list_articles_name, 'abstract' : list_abstracts}\n",
    "    dataframe = pd.DataFrame.from_dict(data)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eea0b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Program\n",
    "\n",
    "list_url = ['https://jurnal.ipb.ac.id/index.php/jikk/issue/archive','https://jurnal.ipb.ac.id/index.php/jikk/issue/archive/2']\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    for url in list_url:\n",
    "        driver.get(url)\n",
    "        driver.maximize_window()\n",
    "\n",
    "        WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, \"//a[@class='title']\")))\n",
    "\n",
    "        while True:\n",
    "            list_title = driver.find_elements(By.XPATH, \"//a[@class='title']\")\n",
    "            \n",
    "            dataframe_full = pd.DataFrame()\n",
    "            \n",
    "\n",
    "            for i in range(len(list_title)):\n",
    "    \n",
    "                time.sleep(2)  \n",
    "\n",
    "                list_title = driver.find_elements(By.XPATH, \"//a[@class='title']\")\n",
    "\n",
    "                title = list_title[i]\n",
    "                driver.execute_script(\"arguments[0].click();\", title)\n",
    "                \n",
    "                list_articles_name = get_articles_name()\n",
    "                \n",
    "                current_url = driver.current_url\n",
    "                \n",
    "                list_articles_link = get_articles_link(current_url)\n",
    "                \n",
    "                list_pdf_articles = get_pdf_articles_link(current_url)\n",
    "                \n",
    "                list_abstracts = get_abstracts(list_articles_link)\n",
    "                \n",
    "                dataframe = get_df(list_articles_name, list_pdf_articles, list_abstracts)\n",
    "                \n",
    "                dataframe_full = pd.concat([dataframe_full, dataframe]).reset_index(drop=True)                \n",
    "                \n",
    "\n",
    "                WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, '//a[@href=\"https://jurnal.ipb.ac.id/index.php/jikk/issue/archive\"]')))\n",
    "\n",
    "                driver.execute_script(\"window.history.go(-1);\")\n",
    "\n",
    "                WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, '//a[@href=\"https://jurnal.ipb.ac.id/index.php/jikk/issue/archive\"]')))\n",
    "\n",
    "            break\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4183114",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_full.to_csv('journal_scrape.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
